# 1장. 사용자 수에 따른 규모 확장성


## 단일 서버 → 대규모 서버

사용자가 늘게 되면 단일 서버로 충분하지 않아짐 

- 단일서버 : 웹, 앱, 데이터베이스, 캐시 등이 서버 한대에서 실행 (현재 스터디룸과 같음)

<details>
<summary>단일 서버 사용자 요청 처리 흐름</summary>
    
    사용자는 도메인 이름을 이용해 웹사이트 접속한다. 
    
    1. 사용자가 Domain Name 을 DNS에 질의 
        1. DNS 는 서드파티 (제 3 사업자 == 가비아 ) 가 유로 서비스로 제공함.
        즉, 우리 시스템의 일부가 아님 
    2. DNS 조회 결과인 IP 주소를 사용자가 반환받게 된다. 
    3. 전달 받은 IP 주소로 HTTP request / 요청을 함 (웹서버에게)
    4. Html || JSON 을 HTTP response 응답을 받는다. (웹서버로 부터)

</details>
    



단일 서버 관점으로 크게 2가지로 나눌 수 있다. 

1. [웹 계층] 웹 / 모바일 트래픽 처리 용도 Client - WebServer
2. [데이터 계층] 데이터베이스 용도  WebServer - DB 

### **Scale-Up vs Scale-Out, 어떤 규모 확장이 유리한가?**
    
    서버로 유입되는 트래픽 양이 적을 땐, Scale-Up(수직적 확장)이 더 좋은 선택 
    
    Why?? → 단.순.함
    
    - BUT, Scale-Up 에는 치명적인 단점 3가지가 있음
        - 규모 확장에 한계
        - 결국 한 대 서버에 모든 게 몰려 있고, 이 서버가 죽으면 → 서비스 전체가 다운됨
        - 자동복구 방안(Automatic Recovery Mechanism) X
            
        자동복구 방안 : 서버나 서비스에 장애가 발생했을 때, 운영자가 직접 개입하지 않아도 시스템이 자동으로 장애를 감지하고 복구 절차를 수행하는 기능
            

> 따라서 , 대규모 애플리케이션의 경우 수평적 규모 확장이 더 적절하다. 

## **웹 계층 의 Scale-Out**

**로드벨런서**
    
    웹 서버의 가용성과 성능을 확보하기 위해서는 로드 밸런서(Load Balancer) 를 활용한 수평적 확장이 필요하다.
    
    스터디룸 아키텍처와 같이 사용자가 단일 웹 서버에 직접 연결되는 구조에서는, 해당 웹 서버가 다운되면 사용자는 웹사이트에 접속할 수 없다. 
    
    또한 특정 시점에 과도한 트래픽이 몰리면 서버의 응답 속도가 급격히 느려지거나, 심한 경우 접속 자체가 불가능해질 수 있다.
    
    이러한 문제를 해결하기 위해서는 웹 서버를 여러 대로 수평적 확장(Scale-Out) 하고, 이를 효율적으로 관리·조율하기 위해 로드 밸런서를 도입한다.
    
    로드 밸런서는 들어오는 트래픽을 Scale-Out된 여러 웹 서버에게 고르게 분산(Load Balancing) 시켜, 특정 서버에 과부하가 집중되지 않도록 한다. 
    
    이 과정을 통해 서비스는 보다 높은 안정성과 가용성을 확보할 수 있다.
    
<details>
    <summary> 로드벨런서 + 사용자 요청 처리 흐름 </summary>
        
        사용자는 도메인 이름을 이용해 웹사이트 접속한다. 
        
        1. 사용자가 Domain Name 을 DNS에 질의한다.
            - 이때 DNS에는 Domain Name ↔ 로드밸런서 공개 IP가 매핑되어 있다.
            
        2. DNS 조회 결과인 로드밸런서 공개 IP 주소를 사용자에게 반환한다.
            - 따라서 클라이언트는 실제 웹 서버의 IP를 모르고, 오직 로드밸런서 IP만 본다.
            - 로드밸런서와 웹 서버는 Private IP 로 통신하여 보안을 강화한다.
            
        3. 사용자는 로드밸런서 공개 IP로 HTTP Request(요청) 을 보낸다.
        4. 로드밸런서는 요청을 받아 내부 알고리즘(Round Robin, Least Connection 등)에 따라 여러 웹 서버 중 하나로 요청을 분산시킨다.
            - 이 과정에서 로드밸런서는 헬스 체크(Health Check) 를 통해 정상 상태인 서버만 대상으로 분산한다.
            
        5. 선택된 웹 서버는 요청을 처리하고 HTTP Response(응답) 을 로드밸런서로 보낸다.
        6. 로드밸런서는 응답을 사용자에게 다시 전달한다.
            - 사용자는 자신이 어느 웹 서버와 통신했는지 알 수 없고, 항상 로드밸런서만 본다.
    
</details> 
    
> 따라서, 로드 밸런서를 도입함으로써 웹 계층에서 발생하는 트래픽 집중 및 단일 서버 장애 문제를 효과적으로 해결할 수 있다.
        
## **데이터 계층의 Scale-Out**
    
웹 계층에서 로드벨런서를 활용해 가용성과 안정성 확보했듯이, 데이터 계층에서도 가용성과 안정성확보가 필요해보인다. 
    
### 데이터 베이스 : RDB vs NoSQL, 어떤 데이터 베이스를 채택할 것인가? 
        
NoSQL 종류

        - key-value store / 키벨류 저장소
        - graph store / 그래프 저장소
        - column store / 칼럼 저장소
        - document store / 문서 저장소
        
        
기본적으로 RDB가 최선이겠지만, 근데! NoSQL이 바람직한 경우도 분명히 있다.
        
#### NoSQL이 바람직한 경우는 언제일까? 
  
- 아주 낮은 응답 지연시간, 실시간성 대두될 때!
    
        - RDB는 Join, 트랜잭션 처리, 스키마 검증 등 여러 단계를 거친다. 쿼리시 오버헤드
        - NoSQL 은 k-v 조회 이거나 Document 기반 단일 접근인 경우, 빠르게 응답 속도 可
  
  → 온라인 게임 순위, 실시간 채팅 메시지
  
                
- 다루는 데이터가 비정형 데이터 인 경우
      
        - RDB는 스키마에 맞게 데이터를 정규화 해야하는데 비정형 데이터는 테이블 구조에 맞추기 어려움
        - NoSQL 은 자유로운 스키마 구조를 제공해 비정형 데이터를 유연하게 저장할 수 있음
                
    → 소셜 미디어 피드, 로그 데이터, IoT 센서 데이터 (json 형태로 그대로 저장)
                
- 데이터를 직렬화, 역직렬화 할 수 있기만 하면 됨
    
        - DB가 데이터를 이해할 필요가 없는 경우
                
- 아주 많은 양의 데이터를 저장할 필요가 있는 경우
  
        - RDB 는 Scale-Out 에 어려움이 있음 & 샤딩 (Sharding) 역시 복잡함
        - NoSQL은 설계 단계에서 분산 시스템을 전제하고 있어, 노드를 추가하면 자동으로 분산 저장 처리 할 수 있음
                    
        ex ) 넷플릭스(Netflix)는 전 세계 스트리밍 로그와 메타데이터를 DynamoDB와 Cassandra에 저장해 확장성 문제를 해결했음 
                    
                
    → 빅데이터 환경, 로그 수집, IoT 센서 네트워크, SNS
    
이러한 상황에서 NoSQL 도입을 위해서, 일반적으로 데이터베이스 다중화(Database Replication) 방식을 사용한다.
    
### 데이터 계층 : 데이터베이스 다중화 (Database Replication)
        
데이터베이스를 다중화할 때는, 데이터베이스를 각각 Master–Slave 구조를 설정하는 것이 일반적이다.
        
    - Master DB: 원본 데이터를 저장하며, 주로 쓰기 연산을 처리한다.
    - Slave DB: Master DB의 데이터를 실시간(또는 일정 주기)으로 복제하여 저장하며, 주로 읽기 연산만 처리한다.
        
    대부분의 애플리케이션은 [쓰기 연산 << 읽기 연산]
    
즉, 읽기 연산의 비중이 훨씬 크기 때문에, 실제 운영 환경에서는 여러 개의 Slave DB를 두고, Master DB는 하나만 두는 경우가 많다.
        
#### **다중화를 통해 무엇을 얻을 수 있는가?**
        
        - 더 나은 성능 :
            - M-S 관계를 통해 R/W 연산이 분산되어 전달된다.
            - 이렇게 되면 병렬로 처리되는 질의 (읽기?) 수가 늘어난다.
        - 안정성 & 가용성 :
            - 지역(물리적) 분산을 통해 안정성을 확보 가능
            - 분산을 통해서 하나의 DB에 장애가 발생하더라도, 다른 DB로 대체 가능

가용성과 확장성을 확보하였다. 이제, 재직중 가장 골머릴 앓았던 latency에 대해서 알아보자.

### **응답 시간 latency**
    
> MSA 에서 많은 레이어들 중, 어디서 어떻게 병목이 발생하는지 몰라, latency 개선에 엄청난 애를 먹었다. 
> 
> 또한 트래픽에 따라 latency가 지수적으로 스파이크가 튀거나 간혹 아예 서버가 죽는 경우가 많았다. 
> 
> 당시 정말 이상한 cron job이 많이 수행되고 있었는데, 이놈을 개선하니 주기적인 스파이크는 해소 할 수 있었다. 
> 
> 또한, 장비 단과 정합성유지를 위해 많은 DB I/O 가 발생하고 있었고, 해당 부분에 cache 를 도입하여 latency 와 DB scale 을 down 하여 비용확보를 할 수 있었다.


#### **latency 개선 방안** 
    
1. 캐시(Cache) 도입
       
        - WebServer ←→ DB 간의 DB I/O 감소
        - DB I/O 는 애플리케이션 전체 성능에 직접적인 영향을 미친다.
        - 자주 조회되는 데이터나 복잡한 연산 결과를 메모리에 저장해, 데이터베이스 접근 횟수를 줄이고 응답 시간을 단축할 수 있다.
            - **cache 유의점**
                
                cache는 어떤 상황이 바람직할까? 
                
                → 데이터의 갱신 ↓ , 데이터 조회 ↑ 인 경우 
                
                만료기한(TTL)은 어떻게 설정해야할까? 
                
                → 캐시는 기본적으로 휘발성 메모리에 저장되므로, 영구적으로 데이터를 보관하는 용도로는 적합하지 않다. 
                
                → TTL을 너무 짧게 설정하면 캐시 적중률 ↓, 캐싱의 의미가 줄어든다. 
                
                → TTL이 지나치게 길면 변경된 데이터가 반영되지 않아 데이터 불일치(Consistency Issue) 가 발생 可
                
                캐시 서버 역시 한대만 둔다면, 단일 장애 지점(SPOF) 이 되어버린다. 
                
                → 따라서 캐시 서버 역시 분산하여야한다.
                
                캐시의 메모리 크기는 어떻게 설정해야할까? 
                
                → 메모리가 너무 작다면, 메모리위 데이터가 자주 밀려나(eviction) 성능 ↓
                
                → 과도하게 큰 메모리를 할당하면 불필요한 자원 낭비가 발생 可
                
                → 그래도, *오버프로비저닝 하여, 캐시 데이터가 급증할시 문제를 방지
                
                데이터 방출 (eviction) 정책은 어떤것을 채택할까? 
                
                → LRU ( 사용한지 가장 오래된 녀석을 방출 )
                
                → LFU ( 사용 빈도가 가장 낮은 녀석을 방출 ) 
                
                → FIFO ( 가장 먼저 들어온 녀석을 먼저 제거 )
                
                *Overprovision의 의미 : 최대 예상 트래픽이나 데이터 증가량을 고려해, 필요한 것보다 더 많은 리소스를 미리 확보하는 전략
    
2. 콘텐츠 전송 네트워크(CDN : Content Delivery Network) 활용 
    
        - Client ←→ S3 혹은 WebServer 간 payload 절감 및 latency 최소화
        - 이미지, CSS, JavaScript와 같은 정적 콘텐츠 요청은 전체 트래픽에서 상당 부분을 차지한다. 이를 CDN으로 오프로드하면 원본 서버의 부하를 줄일 수 있다.
        - 사용자와 가까운 CDN 엣지 서버에서 콘텐츠를 제공하므로 응답 지연이 줄어들고, 서비스의 안정성과 확장성이 강화된다.
   
            - CDN 동작 흐름
                1. 사용자가 A.png 에 엑세스 
                2. (가장 가까운) CDN 서버에 A.png가 없다면, CDN 서버에서 웹서버 혹은 S3 에 요청 
                3. CDN 서버가 웹서버로 부터 A.png 를 받고 CDN에 저장 
                4. CDN 서버가 사용자 에게 A.png 반환 
                5. 다른 사용자가 A.png 에 엑세스 
                6. CDN 서버가 다른 사용자 에게 A.png 반환
   
            - CDN 유의점
                
                비용 
                
                → CDN은 보통 서드파티 프로바이더(제3의 사업자)에 의해 운영된다.
                
                → CDN I/O 에 따라 요금을 지불해야함
                
                → 자주 사용되지않는 캐싱하지말고, 비용을 아끼자 
                
                CDN 장애에 대한 대처 방안 
                
                → CDN 자체가 죽었을 때, 애플리케이션의 동작을 고려해야한다.
                
                → 일시적으로 CDN이 응답하지 않는 경우, 문제를 감지하여, 원본 서버로 부터 직접가져올 수 있도록 구성해야함 
                
                만료기한 설정 
                
                → 잘하자 

            
### **Stateless 웹 계층**
    
    세션 데이터를 웹 계층으로 부터 분리하고 지속성 데이터 보관소에 저장하도록 한다. 
    
    지속성 (공유) 저장소는 RDB , Memcahced/Redis 같은 캐시시스템 , NoSQL 일 수 있다.


#### Stateful vs Stateless
        
**Stateful** 
    
    - 서버가 각 클라이언트의 상태( 세션, 로그인 정보, 장바구니 등)를 직접 메모리에 저장
    - 특정 사용자가 항상 같은 서버에 연결되어야 정상동작
    - 서버가 죽으면 세션정보 삭제
    
**Stateless** 
    
    - 웹 서버가 클라이언트 요청을 상태와 분리하여 독립적으로 처리한다.
    - 클라이언트의 상태(세션, 로그인 정보 등)는 서버 메모리에 직접 저장하지 않고,
        - 외부 세션 저장소(예: Redis, DB) 에 관리하거나,
        - 클라이언트 측(Local Storage, Cookie) 에 저장한다.
    - 이렇게 하면 사용자가 어느 서버로 요청을 보내도 동일한 상태를 참조할 수 있어, 스케일 아웃(Load Balancing) 과 자동 복구(Failover) 에 유리하다.
    
    - 단, Local Storage에 토큰/세션 정보를 저장하는 경우
        
        보안상 XSS 취약점에 노출될 수 있으므로, 실무에서는 보통 HttpOnly Cookie + 서버/세션 스토어 방식이 더 안전하다.
    

나의 웹사이트가 전세계의 주목을 받을 경우를 대비해, 여러 데이터 센터를 활용하자 


### - **데이터센터**
    
    Region (AWS 웨스트 버지니아) 을 여러개를 활용하는 경우를 알아보자 
    
    일반적으로 (장애가 없는 상황에서) 사용자는 가까운 Region 으로 안내된다. 
    
    이러한 절차를 geoDNS-routing이라한다. 
    
    geoDNS 는 사용자 위치에 따라 도메인의 이름을 어떤 IP 주소로 변환할지 결정할 수 있도록 해주는 DNS 서비스이다. 이 지리적 라우팅은  로드 벨런서가 관장함 
    
    이처럼 다중 데이터 센터 아키텍처를 만들려면, 
    
    1. 트래픽 우회 : 올바른 데이터센터로 트래픽을 보내는 방법 / geoDNS는 가까운 곳으로 보냄
    2. 데이터 동기화 : 데이터 센터마다 별도의 데이터베이스를 사용한다면, 장애가 생겨서 다른 Region 의 데이터센터를 안내 받았을 때, 찾는 데이터가 없는 경우가 있을 수 있음 
        
        → 이를 해결하기위해서, 데이터 센터를 여러개두는 것,, 
        
    3. 테스트와 배포 : 여러 데이터 센터를 사용한다면, 여러 위치에서 테스트 해봐야한다. 한편 자동화된 배초도구는 모든 데이터 센터에 동일한 서비스가 설치되도록 하는데 중요한 역할을 한다. 
    
    3가지 문제를 해결해야한다. 
    
     
    

> 또한, 더 큰 규모의 확장을 위해서는 시스템의 컴포넌트를 분리해, 각기 독립적으로 확장할 수 있어야한다.  ⇒ MSA
> 분산시스템의 문제들을 해결하기위해서 “메시지 큐”는 핵심전략이 될 수 있다.

### **메시지 큐**
    
메시지 큐는 비동기 통신을 지원하는 미들웨어 컴포넌트로서,
    
    - 메시지 무손실 보관: 메시지를 소비자가 꺼낼 때까지 안전하게 보관한다.
    - 비동기 처리: 생산자와 소비자가 동시에 동작하지 않아도 메시지를 주고받을 수 있다.
    - 버퍼 역할: 생산자가 메시지를 빠르게 발행하더라도 소비자가 처리 속도에 맞춰 순차적으로 가져갈 수 있도록 중간에서 완충(buffer) 역할을 한다.

<details>
<summary>메시지 큐 기본 아키텍쳐</summary>
메시지 큐 기본 아키텍쳐
    
    
    											 / -[소비]-> 소비자
    생산자 -[발행]-> 메시지 큐 < 
    											 \ <-[구독]- 소비자
    
    
**생산자(Producer, 발행자)**
    
    - 입력 서비스 역할. 메시지를 만들어 메시지 큐에 발행(Publish)한다.
    
**소비자(Consumer, 구독자)**
    
    - 메시지 큐와 연결된 서비스/서버로, 필요한 메시지를 구독(Subscribe)하고 처리한다.
    
</details>

    생성자는 소비자 프로세스가 다운되어있어도 메시지를 발행 할 수 있다. 
    소비자는 생성자 서비스(서버)가 다운되어있어도 메시지를 수신할 수 있다. 
    
메시지 큐를 이용하면, 서비스(or 서버)간 결합이 느슨해져, 규모확장성이 보장된 안정적인 애플리케이션을 구성할 수 있다.
    

<details>
<summary>메시지 큐 적용 예시</summary>
        
    (Ex : RabbitMQ, Kafka, AWS SQS )
        
    1. 사용자가 사진 보정 요청을 보냅니다. (예: A.jpg → 크롭 요청)
    2. 웹 서버(생산자)는 이 요청을 **메시지 큐에 넣습니다.**
        - 이 시점에서 사용자에게는 “작업이 접수됨” 이라고 빠르게 응답할 수 있음.
        - 즉, 서버는 무거운 연산을 직접 즉시 처리하지 않습니다.
    3. **보정 작업 프로세스(소비자, worker)** 가 메시지 큐에서 작업(job)을 꺼내 실행합니다.
        - 크롭, 샤프닝 같은 연산을 실제로 수행.
        - 여러 대의 worker 프로세스를 두면, 동시에 여러 사진을 병렬 처리할 수도 있음.
    4. 처리가 끝나면 결과 이미지를 저장해 두고, 사용자는 나중에 해당 이미지를 확인할 수 있습니다.
    
몇 개 서버에서 실행되는 소규모 웹사이트를 만들때는 로그나 매트릭, 자동화 같은 것은 하면 좋지만, 꼭 할 필요는 없다. 하지만, 웹사이트와 함께 사업 규모가 커지고 나면, 그런 도구에 필수적으로 투자해야한다.
    
    로그 : 에러로그는 서버(서비스) 단위로 모니터링 할 수 도 있고, 로그를 단일 서비스로 모아주는 도구를 활용하면 더욱 편리하게 검색하고 조회 할 수 있다. 
    
    매트릭 : 메트릭을 잘 수집하면, 사업 현황에 관한 유용한 정보를 얻을 수 도 있고, 시스템의 현재 상태를 손쉽게 파악할 수도 있다. 메트릭 가운데 특히 유용한 것을 몇 가지 살펴보면 다음과 같다. 
    
    호스트 단위 메트릭: CPU, MEM, disk IO
    
    종합 (Aggregated) 메트릭 : 데이터베이스 계층의 성능 , 캐시 계층의 성능 
    
    CI : 개발자 생성한 코드를 자동으로 어떤 검증 절차를 거치도록하여 쉽게 문제를 감지할 수 있고, 빌드, 테스트, 배포 등의 절차를 거쳐 개발 생산성을 크게 향상 시킬 수있음 
    
    - with 메시지 큐 (웹 서버 → 작업 서버)
    웹서버에서 무거운동작을 다하지않고 비동기로 작업서버에게 throw

</details>
        
---
    
### DBMS scale out :샤딩
        
샤딩키를 어떻게 정하지?
    
    → 샤딩키 (== 파티션키)  샤드 들이 파티셔닝 되있잖아! 
    
    → 속성이 엔티티마다 하나씩 추가되나? (좀 더 공부하기, 우선순위는 낮음)
        
<details>
<summary>샤딩을 위해서 극복해야할 것들</summary>
        
    1. 데이터의 재 샤딩 : 샤드 내에 데이터가 너무 많아진 경우  or  샤드 간 분포가 고르지 못한 경우 
    
    2. celebrity 문제 (hotspot 키 문제):  특정 샤드에 쿼리가 몰려 서버에 과부하가 걸리는 문제 
    
    3. 조인과 비정규화 문제 : 하나의 DB를 여러 샤드로 쪼개면, 여러 샤드에 걸친 데이터를 조인하기 어려워진다. 
        → 해결법은 비정규화를 통해 조인 결과테이블을 만들어두어야함 
> 너무 빡시다. 샤딩을 해야하는 정도라면,, 설계가 잘못된 것이 아닐까? 
</details>
