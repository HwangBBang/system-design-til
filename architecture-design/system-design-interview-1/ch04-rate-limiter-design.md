# 4장. 처리율 제한 장치의 설계

## 처리율 제한 장치 (rate limiter)란?

API 요청 횟수가 제한 장치에 정의된 임계치를 넘으면 블락 시켜주는 녀석

<details>
    <summary>예시)</summary>

    - 사용자는 초당 2회 이상글을 쓸 수 없다.
    - 같은 IP 주소로는 하루에 10개이상 계정을 생성할 수 없다.
    - 같은 디바이스로 리워드는 2회 이상 받을 수 없다.
</details>




### 처리율을 제한하면 뭐가 좋을까?

    → Denial of Service (DoS) 공격에 의한 자원 고갈 방지
    → 비용 절감
    → 과부하 막기, 봇 방지

많은 제품들의 API 에는 어떤 형태로든 처리율 제한장치(rate limiter)를 갖고 있다.

이렇게 함으로써 DoS공격을 방지할 수있고, 비용을 절감 할 수 있다.

### 처리율 제한 장치는 어디에 두어야할까?

이 역시 정답은 없지만, 클라이언트 사이드에 두었을 경우 부터 살펴보자.

- 클라이언트 사이드에 둔다면,

        일반적으로 클라이언트는 처리율 제한을 안정적으로 걸 수 있는 장소가 되지 못한다.

        클라이언트의 요청은 쉽게 위변조가 가능하기 때문이다.

        또한, 모든 클라이언트의 구현을 통제하는 것도 매우 어려운 일일 것이다.

- 서버 사이드에 둔다면,

        정교하고 신뢰할 수 있는 제어가 가능하다, 하지만 애플리케이션에 도달하기전에
        이미 로드밸런서, API게이트웨이, 웹서버 레이어에서 리소스를 소비한다.
        즉, 의미있는 과부하 방지는 어렵다.
        또한, 도메인 로직과 섞이게되면 복잡도 증가는 물론이고, 정책 변경도 어려워지므로 별도 모듈로 분리하거나 공통 컴포넌트로 추상화하는 설계가 필요하다.

        그렇기에 그냥 전용 미들웨어로 뽑아서, 미들웨어 중 가장 앞단(트래픽 진입점)에 둔면 합리적일 것이다.

> 참고로 ,, API 게이트웨이가 처리율 제한을 지원하는 미들웨어이기도하다. ^^

## 처리율 제한 알고리즘

### 토큰 버킷 알고리즘 (token bucket)
  
  > 인터넷 기업들이 보편적으로 사용함
  - **동작원리** :
    
        토큰 버킷은 지정된 용량을 갖는 컨테이너,
        이 버킷에는 설정된 양의 토큰이 주기적으로 채워진다.
        토킨이 꽉찬 버킷에는 더 이상 토큰이 추가되지않는다.
        요청이 처리될 때 마다 하나의 토큰을 사용하며,
        토큰이 버킷에 더이상 존재하지않는 경우 해당 req 은 drop 한다.
        토큰 버킷 알고리즘은 2가지 파라미터를 받는다. (버킷 size , 토큰 공급률)
    - 버킷 size : 버킷에 담을 수 있는 토큰의 최대 갯수
    - 토큰 공급률(refill rate) : 초당 몇 개의 토큰이 버킷에 공급되는지
  
  - **버킷은 몇 개를 사용해야할까?**
    → 공급 제한 규칙에 따라 달라진다.

    - **1) 엔드포인트별 버킷** → 사용자 마다 3개의 버킷을 두어야한다.
      사용 사례(사용자 기준):
      “하루에 한 번 포스팅” → 용량(capacity)=1, 재충전(refill)=1/일
      “친구 추가 150명/일” → capacity=150, refill=150/일
      “좋아요 5회/일” → capacity=5, refill=5/일
      의미: 같은 사용자라도 각 엔드포인트 별로 다른 속도/버스트를 허용.

    - **2) IP별 버킷** → IP 주소마다 버킷을 하나씩 할당해야한다.
      - DDoS/스크레이핑 억제, 인증 전 구간에서의 남용 방지에 유효.
      - 주의: 이동통신·회사망 NAT로 **여러 사용자가 하나의 IP**를 공유할 수 있음.
      - 과도한 오탐 방지를 위해 IP 한도는 비교적 느슨하게, 사용자 한도는 더 타이트하게 잡는 식으로 병행 구성.
        
    - **3) 시스템 전역(글로벌) 버킷** → 하나의 글로벌 버킷
      - “전체 QPS 10,000 제한” 같은 **백엔드 보호용 세이프티 넷**.
      - 예: capacity=10,000, refill=10,000 tokens/sec (버스트 허용치와 스무딩 전략에 맞게 조정).
     
        
    → 결론: 셋 중 **하나만** 택하는 게 아니야!!
    - 전역(Global) 버킷: 플랫폼 보호
    - 주체별(Per-User/Token/IP) 버킷: 공정성·남용 방지
    - 엔드포인트별(Per-Endpoint) 버킷: 비즈니스 제약을 **동시에** 적용하는 것이 일반적

  
  - **장점 & 단점 :**
    구현 쉽다.
    메모리 측면 효율적
    짧은 시간에 집중되는 트래픽 처리 가능 (버킷에 남은 토큰이 있다면, 요청은 시스템에 전달될 거야)
    매개변수 두 가지( 버킷 사이즈와 , 리필률 ) 을 적절히 튜닝하는게 어렵다.

### 누출 버킷 알고리즘 (leaky bucket)
  
  > 요청 처리율이 고정
  - **동작 원리** :
    
        누출 버킷 알고리즘은 일반적으로 FIFO 큐로 구현.
        요청이 도착하면 큐가 가득차 있는지 확인,
        빈자리가 있다면, 큐에 (req)를 추가
        빈자리가 없다면, req를 drop
        지정된, 시간 마다 큐에서 req를 poll해 처리함
        누출 버킷 알고리즘은 2가지 파라미터를 받는다 (큐 (버킷) 사이즈, 처리율)
    - 큐 size : req를 담아 둘 queue 의 사이즈
    - 처리율(outflow rate) : 초당 몇 개의 항목을 처리할 지?
      
  - **장점 & 단점**
    큐의 크기가 제한되어 있으니, 메모리 사용 측면에서 효율적
    고정된 처리율을 갖고 있기에 안정적인 출력이 필요한 경우 적합
    단시간에 과트래픽이 오는 경우 큐에는 요청이 쌓이고, 버려지는 최신 요청들이 많아짐
    매개변수 두 가지( 큐 사이즈와 , 처리율 ) 을 적절히 튜닝하는게 어렵다.

- 고정 윈도 카운터 알고리즘 (p. 61)
- 이동 윈도 카운터 알고리즘
- 이동 윈도 로그 알고리즘

- **1단계. 문제 이해 및 설계 범위 확정**
  처리율 제한 장치
  → 어떤 사이드 처리율 제어인가? (서버 측?, 클라이언트 측?)
  → 어떤 기준으로 제어해야하는가? ( IP 주소? , 사용자 ID?)
  → 시스템 규모는 어느정도인가? (스타텁?, 대기업?)
  → 시스템이 분산 환경에서 동작하는가?
  → 처리율 제한 장치는 독립적인가? 종속적(코드에 포함)인가?
  → 사용자가 처리율 제한 장치에 의해 제한된 것을 알아야하는가?

- **2단계. 개략적인 설계안 제시 및 동의 구하기**
  
    일단은 기본적인 클라이언트-서버 통신 모델을 사용
    MSA의 경우, API 처리율 제한 장치는 API Gateway 라는 컴포넌트에 구현된다.
    API Gateway는 처리율 제한을 지원하는 미들웨어

  > 직접 처리율 제한 장치를 구현하는 건 빡세다 ~ 그냥 상용 API 게이트웨이 써라

  
  직접 구현한 경우를 알아보자.

        처리율 제한 컨셉 자체는 간단하다. “카운팅하고 한도를 넘었다면 거부하자.“
        그럼 이 카운터는 어디에 보관해야할까?
        DB? → disk 접근은 느려! 사용 X
        Redis (InMemory DB) , 빠르고 + TTL 지원 + INCR 지원
        INCR 은 메모리에 저장된 카운터 값을 1만큼 증가
  

  ```
  														 / --> API 서버
  클라이언트 -> 처리율 제한 미들웨어 <
  														 \ --> Redis
  ```

  1. 클라이언트가 미들웨어에 request
  2. 미들웨어는 레디스의 지정 버킷에서 카운터를 가져와서 한도에 도달했느지 검사
  3. 한도에 도달했다면 거부, 도달하지않았다면, request 를 API 서버로 전달
  4. 카운터를 증가시킨 후 다시 redis 에 저장


- **3단계. 상세 설계**
  
  #### 그럼 2가지 상세 사항을 어떻게해야할까?
  - 처리율 제한 규칙은 어떻게 만들어지고, 어디에 저장할까?
  - 처리가 제한된 요청들은 어떻게 처리해야할까?
  → 처리율 제한 규칙은 configuration file 형태로 디스크에 저장한다.
  → 어떤 요청이 한도제한에 걸리면 429(Too Many Request)를 (미들웨어 → 클라이언트)가 보낸다.
  → 경우에 따라서는 drop 된 req 를 큐에 담아 나중에 처리한다.

  #### 클라이언트가 자신이 보낸 req에 throttle 이 걸리는지 어떻게 감지하지?
  → Response HEADER를 보고 알 수 있음

  `X-Ratelimit-Remaining` : 윈도 내에 남은 처리 가능 요청 수
  `X-Ratelimit-Limit` : 매 윈도마다 클라이언트가 전송할 수 있는 요청의 수
  `X-Ratelimit-Retry-After` : 한도 제한에 걸리지않으려면 몇 초 뒤에 요청을 다시보내야하는지

  단일 서버 처리율 제한 규칙 장치 구현은 어렵지 않다,,
  다중 서버와 병렬 스레드를 지원하는 시스템은 아래 2가지 문제를 해결해야한다.

  - Race Condition (경쟁 조건)
    레이스 컨디션의 널리 알려진 해결책인 lock으로 해결이 가능하지만,
    Lock 은 시스템 성능을 상당히 떨어트린다.
    그럼 대안책으로 무엇을 써야할까? → Redis 를 쓰자.
    Redis는 단일 스레드(single-threaded event loop) 로 동작하기 때문에,
    - INCR, DECR 같은 연산은 읽기 → 연산 → 저장 과정을 원자적(atomic) 으로 실행한다.
    - 따라서 동시에 수천 개 요청이 와도, 내부적으로 순차 처리되므로 Race Condition(경쟁 조건) 이 발생하지 않는다!
    - 
  
  - 동기화
    대규모 시스템에서는 처리율 제한(rate limiting) 장치도 수평 확장되어야 한다.
    다만 무상태(Stateless) 웹 계층만으로는 개별 클라이언트의 요청 이력을 공유할 수 없기 때문에 인스턴스 간 **동기화**가 필요합니다.
    → 이를 위해 세션 고정로 우회할 수 있으나, 이는 확장성과 유연성을 저해한다.
    → 중앙 집중형 공유 저장소로 **Redis** 를 사용해 클라이언트별 토큰/카운터 상태를 관리하고, 모든 게이트웨이/웹 인스턴스가 동일한 제한 상태를 참조하도록 설계한다.

- **4단계. 마무리**

  ##### hard 처리율제한, soft 처리율제한 을 알아보자
  - hard 처리율제한: 요청 개수가 임계치를 절대 넘을 수 없다.
  - soft 처리율제한: 요청 개수가 잠시 동안은 임계치를 넘을 수 있다.
  - 
  
  ##### 다양한 계층에서의 처리율 제한 을 알아보자
  - 애플리케이션 계층 (OSI 7계층) 에서 처리율 제한을 알아보았는데, 다른 계층에서도 가능하다.
  - 네트워크 계층(OSI 3계층)의 IP TABLE 을 이용하더라도 ip 주소에 대한 제한을 걸 수 있음
  
  ##### 처리율 제한을 회피하는 방법, 클라이언트는 어떻게 설계하는 것이 최선일까?
  - 클라이언트 측 캐시를 사용하여 API 호출 횟수를 줄인다.
  - 처리율 제한의 임계치를 이해하고, 짧은 시간 동안 너무 많은 메시지를 보내지 않도록한다.
  - 예외나 에러를 처리하는 코드를 도입하여 클라이언트가 예외적 상황으로 부터 우아하게 복구될 수 있도록한다.
  - 재시도 로직을 구현할 때 충분한 백오프 시간을 둔다.
